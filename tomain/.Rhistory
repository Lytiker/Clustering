daisy_csv=read_table('/media/anne/My Passport/python_files/small_daisymatrix.csv')
library(cluster)
library(readr)
library(gplots)
daisy_csv=read_table('/media/anne/My Passport/python_files/small_daisymatrix.csv')
df= as.matrix(daisy_csv)
df= scale(df)
heatmap<-heatmap(df, keep.dendro=TRUE)
daisy_csv=read_csv('/media/anne/My Passport/python_files/train_daisymatrix.csv')
daisy_csv=read_csv('/media/anne/My Passport/python_files/small_daisymatrix.csv')
df= as.matrix(daisy_csv[-1,])
View(daisy_csv)
View(df)
df= as.matrix(daisy_csv)
df= scale(df)
install.packages('raster')
install.packages('fastcluster')
install.packages("factoextra")
install.packages('dbscan')
library(dbscan)
library(devtools)
install_github("mhahsler/dbscan")
install.packages('dbscan')
library(ggplots)
install.packages('ggplots')
library(fpc)
install.packages('fpc')
library(ggplot2)
library(factoextra)
install.packages("factoextra")
install.packages("factoextra")
table_test=fread('/media/anne/My Passport/python_files/small_daisymatrix.csv')
library(data.table)
table_test=fread('/media/anne/My Passport/python_files/small_daisymatrix.csv')
dist=as.dist(table_test)
result=dbscan(dist, eps = 8, MinPts = 2)
library(dbscan)
result=dbscan(dist, eps = 8, MinPts = 2)
sil=silhouette(result$cluster, dist)
library(cluster)
sil=silhouette(result$cluster, dist)
library(ggplot2)
library(fpc)
library(lattice)
library(cluster)
library(readr)
library(raster)
library(ggplot2)
library(fpc)
library(fastcluster)
library(data.table)
library(dbscan)
library(lattice)
library(factoextra)
sil=silhouette(result$cluster, dist)
result=dbscan(dist, eps = 8, minPts = 2)
result=dbscan(dist, eps = 8, minPts = 3)
result=dbscan(dist, eps = 8)
sil=silhouette(result$cluster, dist)
plot(sil)
result=dbscan(dist, eps = 8, showplot = 1)
sil=silhouette(result$cluster, dist)
plot(sil)
dist=as.dist(table_test)
result=dbscan(dist, eps = 8, showplot = 1)
sil=silhouette(result$cluster, dist)
plot(sil)
window()
windows()
plot(sil)
summary(sil)
result=dbscan(dist, eps = 1, showplot = 1)
sil=silhouette(result$cluster, dist)
summary(sil)
plot(sil)
table=fread('/media/anne/My Passport/python_files/train_daisymatrix.csv')
dist=as.dist(table)
result=dbscan(dist, eps = 8, showplot = 1)
data=fread('/media/anne/My Passport/python_files/training/clustershtest.csv')
library(readr)
library(data.table)
data=fread('/media/anne/My Passport/python_files/training/clustershtest.csv')
View(data)
View(data)
View(data)
data=fread('/media/anne/My Passport/python_files/training/clustershtest.csv')
clusters=data$hypertools_Cluster
View(data)
fullframe=read_csv('/media/anne/My Passport/python_files/training/mi_trueattr.csv')
library(data.table)
fullframe=fread('/media/anne/My Passport/python_files/training/mi_trueattr.csv')
View(fullframe)
View(fullframe)
dataframe=head(fullframe,10)
dataframe$ID <- NULL
dataframe$Worst_diagnosis <- NULL
dataframe$true_labels <- NULL
dataframe$true_labels2 <- NULL
View(dataframe)
View(dataframe)
fullframe=fread('/media/anne/My Passport/python_files/training/mi_trueattr.csv')
dataframe=fullframe
dataframe=head(dataframe, n=1000)
dataframe$ID <- NULL
dataframe$Worst_diagnosis <- NULL
dataframe$true_labels <- NULL
dataframe$true_labels2 <- NULL
dataframe[, c(1:9,19:22,26, 37)] <- lapply(dataframe[, c(1:9,19:22,26, 37)], as.factor)
dataframe[, c(10:12,14,23:25)] <- lapply(dataframe[, c(10:12,14,23:25)], as.logical)
dataframe[, c(13,15:18,27:36)] <- lapply(dataframe[, c(13,15:18,27:36)], as.numeric)
str(dataframe)
daisymatrix = daisy(dataframe, metric='gower')
daisymatrix= as.matrix(daisymatrix)
library(readr)
library(cluster)
library(raster)
library(gplots)
library(fastcluster)
library(data.table)
library(grDevices)
library(Matrix)
daisymatrix = daisy(dataframe, metric='gower')
daisymatrix= as.matrix(daisymatrix)
write.table(val_daisymatrix, '/media/anne/My Passport/python_files/training/train_daisymatrix2.csv', sep=',', col.names= FALSE, row.names = FALSE,qmethod =  "double")
write.table(daisymatrix, '/media/anne/My Passport/python_files/training/train_daisymatrix2.csv', sep=',', col.names= FALSE, row.names = FALSE,qmethod =  "double")
df= scale(daisymatrix)
daisy_clust=cutree(hclust(dist(df)), k=3)
daisy_clust2=cutree(hclust(dist(df)), k=6)
dataframe$ID <- fullframe$ID
dataframe$Worst_diagnosis <- fullframe$Worst_diagnosis
dataframe$daisyclust=daisy_clust
dataframe$daisyclust2=daisy_clust2
View(dataframe)
write_csv(dataframe, '/media/anne/My Passport/python_files/val_daisycluster.csv')
library(data.table)
library(data.table)
system.time(fread('/media/anne/My Passport/python_files/training/train_daisymatrix2.csv'))
library(mice)
datasets = read.csv("output/treated_survey.csv")
setwd("~/Documents/gitfolder/patternclustering/finishing/tomain")
datasets = read.csv("output/treated_survey.csv")
View(datasets)
saved_data=datasets #save original dataframe
datasets$ID = NULL
datasets$birthdate=NULL
datasets$dateres=NULL
method_array = c('polyreg', 'polyreg', 'polyreg', 'polyreg', 'polyreg',
'polyreg', 'polyreg', 'polyreg', 'polyreg', 'logreg','logreg','logreg',
'pmm', 'logreg','pmm', 'pmm', 'pmm', 'pmm', 'polyreg','polyreg',
'polyreg','polyreg','logreg','logreg','logreg','polyreg','pmm','pmm')
fact = c('polyreg', 'logreg') #binary and categorical varables must be factors
factorvars=which(method_array %in% fact) #indexes of variable polyreg or logreg in datasets
head(datasets[factorvars])
ncol(datasets[factorvars])
length(method_array)
length(datasets)
datasets[factorvars]=lapply(datasets[factorvars], factor)
sapply(datasets, class)
tempData=mice(datasets, m=5, maxit=50, method=method_array)
tempData=mice(datasets, m=5, maxit=50, method=method_array)
fact = 'polyreg' #categorical varables must be factors
factorvars=which(method_array %in% fact) #create list of indexes to use polyreg or logreg
ncol(datasets[factorvars])
length(method_array)
length(datasets)
datasets[factorvars]=lapply(datasets[factorvars], factor)
sapply(datasets, class)
tempData=mice(datasets, m=5, maxit=50, method=method_array)
fact = 'logreg' #categorical varables must be factors
factorvars=which(method_array %in% fact) #create list of indexes to use polyreg or logreg
ncol(datasets[factorvars])
length(method_array)
length(datasets)
datasets[factorvars]=lapply(datasets[factorvars], factor)
sapply(datasets, class)
tempData=mice(datasets, m=5, maxit=50, method=method_array)
library(mice)
#load dataset without dependent variables
datasets = read.csv("output/treated_survey.csv")
saved_data=datasets #save original dataframe
datasets$ID = NULL
datasets$birthdate=NULL
datasets$dateres=NULL
#create a list of method for each variable (however a whole lot faster if only one method is used)
method_array = c('polyreg', 'polyreg', 'polyreg', 'polyreg', 'polyreg',
'polyreg', 'polyreg', 'polyreg', 'polyreg', 'logreg','logreg','logreg',
'pmm', 'logreg','pmm', 'pmm', 'pmm', 'pmm', 'polyreg','polyreg',
'polyreg','polyreg','logreg','logreg','logreg','polyreg','pmm','pmm')
fact = c('polyreg','logreg') #categorical varables must be factors
factorvars=which(method_array %in% fact) #create list of indexes to use polyreg or logreg
#change indexed variables to factors and store data in dataframe
##select variables
#ncol(datasets[factorvars])
#length(method_array)
#length(datasets)
##make variables factortype
#datasets[factorvars]=lapply(datasets[factorvars], factor)
#sapply(datasets, class)
#impute dataset
tempData=mice(datasets, m=5, maxit=50, method=method_array)
completedData <- complete(tempData,5) #use first imputation
#insert back rows
completedData$ID<-saved_data$ID
total_set =completedData[,c(28, 1:27)]
completedData$birthdate<-saved_data$birthdate
completedData$dateres<-saved_data$dateres
length(total_set)
with_birthdate = completedData[,c(26,27,28,1:25)]
#save dataset as csv
write.csv(total_set, file="output/total_imputed_surveyset.csv")
write.csv(with_birthdate, file="output/total_imputed_surveyset_wbirth.csv", quote = FALSE, row.names = FALSE)
#checkups
pMiss = function(x){sum(is.na(x))/length(x)*100}
apply(completedData,2, pMiss) #percentage of NaN in dataset
warnings()
str(data)
tempData$imp$q6bbeer
tempData$meth
#plots
install.packages("lattice")
library('lattice')
stripplot(tempData)
densityplot(tempData)
summary(tempData)
library(mice)
#load dataset without dependent variables
datasets = read.csv("output/treated_survey.csv")
saved_data=datasets #save original dataframe
datasets$ID = NULL
datasets$birthdate=NULL
datasets$dateres=NULL
#create a list of method for each variable (however a whole lot faster if only one method is used)
method_array = c('polyreg', 'polyreg', 'polyreg', 'polyreg', 'polyreg',
'polyreg', 'polyreg', 'polyreg', 'polyreg', 'logreg','logreg','logreg',
'pmm', 'logreg','pmm', 'pmm', 'pmm', 'pmm', 'polyreg','polyreg',
'polyreg','polyreg','logreg','logreg','logreg','polyreg','pmm','pmm')
fact = c('polyreg','logreg') #categorical varables must be factors
factorvars=which(method_array %in% fact) #create list of indexes to use polyreg or logreg
change indexed variables to factors and store data in dataframe
#select variables
ncol(datasets[factorvars])
length(method_array)
length(datasets)
#make variables factortype
datasets[factorvars]=lapply(datasets[factorvars], factor)
sapply(datasets, class)
#impute dataset
tempData=mice(datasets, m=5, maxit=50, method=method_array)
completedData <- complete(tempData,5) #use first imputation
#insert back rows
completedData$ID<-saved_data$ID
total_set =completedData[,c(28, 1:27)]
completedData$birthdate<-saved_data$birthdate
completedData$dateres<-saved_data$dateres
length(total_set)
with_birthdate = completedData[,c(26,27,28,1:25)]
#save dataset as csv
write.csv(total_set, file="output/total_imputed_surveyset.csv")
write.csv(with_birthdate, file="output/total_imputed_surveyset_wbirth.csv", quote = FALSE, row.names = FALSE)
#checkups
pMiss = function(x){sum(is.na(x))/length(x)*100}
apply(completedData,2, pMiss) #percentage of NaN in dataset
warnings()
str(data)
tempData$imp$q6bbeer
tempData$meth
#plots
install.packages("lattice")
library('lattice')
stripplot(tempData)
densityplot(tempData)
summary(tempData)
View(datasets)
tempData=mice(datasets, m=5, maxit=50, method=method_array)
fact = c('polyreg','logreg') #categorical varables must be factors
factorvars=which(method_array %in% fact) #create list of indexes to use polyreg or logreg
ncol(datasets[factorvars])
length(method_array)
length(datasets)
datasets[factorvars]=lapply(datasets[factorvars], factor)
sapply(datasets, class)
tempData=mice(datasets, m=5, maxit=50, method=method_array)
tempData=mice(datasets, m=5, maxit=50)#, method=method_array)
library(readr)
library(cluster)
library(raster)
library(gplots)
library(fastcluster)
library(data.table)
dataframe=fread('output/faketrain')
print('loaded')
matrix=as.matrix(dataframe)
print('making heatmap')
pdf('output/heatmap.pdf')
heatmap(matrix, Rowv=NA, useRaster=TRUE)
dev.off()
print('heatmap finished!')
print('making dendogram')
hc=hclust(as.dist(dataframe))
pdf('output/dendogram.pdf')
plot(hc)
dev.off()
labels=cutree(hc, k=5)
print('thank you for your patience :)')
dataframe=fread('output/faketrain.csv')
library(readr)
library(cluster)
library(raster)
library(gplots)
library(fastcluster)
library(data.table)
dataframe=fread('output/faketrain.csv')
print('loaded')
matrix=as.matrix(dataframe)
print('making heatmap')
pdf('output/heatmap.pdf')
heatmap(matrix, Rowv=NA, useRaster=TRUE)
dev.off()
print('heatmap finished!')
print('making dendogram')
hc=hclust(as.dist(dataframe))
pdf('output/dendogram.pdf')
plot(hc)
dev.off()
labels=cutree(hc, k=5)
print('thank you for your patience :)')
View(datasets)
View(dataframe)
View(matrix)
heatmap(matrix, Rowv=NA, useRaster=TRUE)
